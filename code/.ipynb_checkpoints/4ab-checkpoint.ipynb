{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce5df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths:\n",
      "Decode input path: ..\\data\\decode_input.txt\n",
      "Train struct path: ..\\data\\train_struct.txt\n",
      "Model path: ..\\data\\model.txt\n",
      "Train data path: ..\\data\\train.txt\n",
      "Test data path: ..\\data\\test.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import os\n",
    "\n",
    "# Base path where your data resides, relative to your code directory\n",
    "base_data_path = os.path.join(\"..\", \"data\")\n",
    "\n",
    "# Define file names\n",
    "decode_input_file = \"decode_input.txt\"\n",
    "train_struct_file = \"train_struct.txt\"\n",
    "model_file = \"model.txt\"\n",
    "train_data_file = \"train.txt\"\n",
    "test_data_file = \"test.txt\"\n",
    "parameter_file = \"Parameters\"\n",
    "\n",
    "# Build full paths by appending file names to the base data path\n",
    "decode_input_path = os.path.join(base_data_path, decode_input_file)\n",
    "train_struct_path = os.path.join(base_data_path, train_struct_file)\n",
    "model_path = os.path.join(base_data_path, model_file)\n",
    "train_data_path = os.path.join(base_data_path, train_data_file)\n",
    "test_data_path = os.path.join(base_data_path, test_data_file)\n",
    "parameter_path = os.path.join(\"..\", \"results\", parameter_file)\n",
    "\n",
    "# Now you can use these paths in your code\n",
    "print(\"File paths:\")\n",
    "print(\"Decode input path:\", decode_input_path)\n",
    "print(\"Train struct path:\", train_struct_path)\n",
    "print(\"Model path:\", model_path)\n",
    "print(\"Train data path:\", train_data_path)\n",
    "print(\"Test data path:\", test_data_path)\n",
    "\n",
    "\n",
    "\n",
    "def read_decode_input(file_path = decode_input_path):\n",
    "    \"\"\"\n",
    "    Reads the decode_input data from the file.\n",
    "    Each line represents one letter with 128 elements.\n",
    "    There are 26 weight vectors each with 128 elements and a transition matrix T with size 26x26.\n",
    "    The transition matrix T is in row-major order.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    X = np.array(raw_data[:100 * 128], dtype=float).reshape(100, 128)\n",
    "    W = np.array(raw_data[100 * 128:100 * 128 + 26 * 128], dtype=float).reshape(26, 128)\n",
    "    T = np.array(raw_data[100 * 128 + 26 * 128:-1], dtype=float).reshape(26, 26)\n",
    "    T = np.swapaxes(T, 0, 1)\n",
    "    \n",
    "    print(\"Shapes of decode input:\")\n",
    "    print(\"X:\", X.shape, \"W:\", W.shape, \"T:\", T.shape)\n",
    "    #print(\"Top 5 rows of X:\\n\", X[:5])\n",
    "\n",
    "    return X, W, T\n",
    "\n",
    "def read_train_struct(file_path = train_struct_path):\n",
    "    \"\"\"\n",
    "    Reads the train_struct data from the file.\n",
    "    Each line represents a label and a feature vector (in a sparse representation).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    for line in raw_data[:-1]:  # The last element is empty\n",
    "        line = line.split(\" \")\n",
    "        dataY.append([int(line[0]) - 1, int(line[1][4:])])\n",
    "        datax = np.zeros(128, dtype=int)\n",
    "        for f1 in line[2:]:\n",
    "            idx, val = f1.split(\":\")\n",
    "            datax[int(idx) - 1] = int(val)\n",
    "        dataX.append(datax)\n",
    "    \n",
    "    dataX_np = np.array(dataX, dtype=int)\n",
    "    print(\"Shapes of train_struct:\")\n",
    "    print(\"dataX:\", dataX_np.shape, \"dataY length:\", len(dataY))\n",
    "    #print(\"Top 5 rows of dataX:\\n\", dataX_np[:5])\n",
    "    \n",
    "    return dataX_np, dataY\n",
    "\n",
    "def read_model(file_path = model_path):\n",
    "    \"\"\"\n",
    "    Reads the model data from the file.\n",
    "    The data consists of weight vectors for each label and a transition matrix T.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    W = np.array(raw_data[:26 * 128], dtype=float).reshape(26, 128)\n",
    "    T = np.array(raw_data[26 * 128:-1], dtype=float).reshape(26, 26)\n",
    "    T = np.swapaxes(T, 0, 1)\n",
    "    \n",
    "    print(\"Shapes of model data:\")\n",
    "    print(\"W:\", W.shape, \"T:\", T.shape)\n",
    "    #print(\"Top 5 rows of W:\\n\", W[:5])\n",
    "    \n",
    "    return W, T\n",
    "\n",
    "def read_train(file_path = train_data_path):\n",
    "    \"\"\"\n",
    "    Read the training data from the file.\n",
    "    Each row corresponds to an example and is split into the label and the feature vector.\n",
    "    \"\"\"\n",
    "    from string import ascii_lowercase\n",
    "    mapping = {letter: idx for idx, letter in enumerate(ascii_lowercase)}\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    tempX, tempY = [], []\n",
    "    for row in raw_data[:-1]:\n",
    "        row = row.split(\" \")\n",
    "        tempY.append(mapping[row[1]])\n",
    "        tempX.append(np.array(row[5:], dtype=float))\n",
    "        if int(row[2]) < 0:  # End of sequence\n",
    "            dataX.append(np.array(tempX))\n",
    "            dataY.append(np.array(tempY, dtype=int))\n",
    "            tempX, tempY = [], []  # Reset for the next sequence\n",
    "\n",
    "    print(\"Number of training sequences:\", len(dataX))\n",
    "    print(\"First 5 sequences' labels:\\n\", dataY[:5])\n",
    "    \n",
    "    return list(zip(dataX, dataY))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_test(file_path = test_data_path):\n",
    "    \"\"\"\n",
    "    Reads the test data from the file.\n",
    "    Each row corresponds to an example and is split into the label and the feature vector.\n",
    "    The function assumes that each example ends when a row with the third column less than 0 is encountered.\n",
    "    \"\"\"\n",
    "    from string import ascii_lowercase\n",
    "    mapping = {letter: idx for idx, letter in enumerate(ascii_lowercase)}\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    tempX, tempY = [], []\n",
    "    for row in raw_data[:-1]:  # Skip the last empty line if it exists\n",
    "        row = row.split(\" \")\n",
    "        tempY.append(mapping[row[1]])\n",
    "        tempX.append(np.array(row[5:], dtype=float))\n",
    "        if int(row[2]) < 0:  # Check for the end of a sequence\n",
    "            dataX.append(np.array(tempX))\n",
    "            dataY.append(np.array(tempY, dtype=int))\n",
    "            tempX, tempY = [], []  # Reset for the next sequence\n",
    "\n",
    "    print(\"Number of test sequences:\", len(dataX))\n",
    "    print(\"First 5 sequences' labels:\\n\", dataY[:5])\n",
    "\n",
    "    return list(zip(dataX, dataY))\n",
    "\n",
    "def read_test_decoder_modified(file_path = test_data_path):\n",
    "    \"\"\"\n",
    "    Reads the test data for decoding and returns a NumPy array\n",
    "    where each sub-array from the list becomes a row in the final\n",
    "    two-dimensional array. This function only extracts the features\n",
    "    and does not deal with the labels.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        raw_data = file.read().strip().split('\\n')\n",
    "\n",
    "    # Initialize an empty list to store all feature vectors\n",
    "    dataX = []\n",
    "    \n",
    "    for row in raw_data:\n",
    "        if row:  # Skip any empty lines\n",
    "            features = row.split(' ')[5:]  # Features start from the 6th element in the row\n",
    "            feature_vector = list(map(float, features))  # Convert string features to float\n",
    "            dataX.append(feature_vector)\n",
    "\n",
    "    # Convert the list of lists (features for each word) into a 2D NumPy array\n",
    "    dataX_np = np.array(dataX)\n",
    "\n",
    "    print(\"Shape of test data for decoder:\", dataX_np.shape)\n",
    "    print(\"Top 5 feature vectors:\\n\", dataX_np[:5, :])\n",
    "\n",
    "    return dataX_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae46cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_log_p(X, y, W, T):\n",
    "    \"\"\"\n",
    "    Computes the log probability of a sequence of labels given inputs X and parameters W, T.\n",
    "    \n",
    "    Parameters:\n",
    "    X : 2D array where each row is the feature vector for one observation.\n",
    "    y : 1D array of labels corresponding to the observations in X.\n",
    "    W : Weight matrix where each row corresponds to the weights for one label.\n",
    "    T : Transition matrix where T[i, j] is the transition weight from label i to label j.\n",
    "    \n",
    "    Returns:\n",
    "    log probability of the label sequence given the inputs and parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    alpha_len = 26  # Alphabet size; ideally passed as a parameter for flexibility\n",
    "    \n",
    "    # Initialize the sum of numerator terms for log probability calculation\n",
    "    sum_num = numpy.dot(W[y[0]], X[0])  # Initial state score\n",
    "    for i in range(1, X.shape[0]):\n",
    "        # Add scores for observed states and transitions\n",
    "        sum_num += numpy.dot(W[y[i]], X[i]) + T[y[i-1], y[i]]\n",
    "    \n",
    "    # Initialize the forward trellis for dynamic programming\n",
    "    trellisfw = numpy.zeros((X.shape[0], alpha_len))\n",
    "    # Temporary storage for computations at each step\n",
    "    interior = numpy.zeros(alpha_len)\n",
    "    # Messages used in the forward pass for dynamic programming\n",
    "    messages = numpy.zeros((26, 26))\n",
    "\n",
    "    # Compute forward messages\n",
    "    for i in range(1, X.shape[0]):\n",
    "        # Compute interior scores based on current observation and previous states\n",
    "        numpy.matmul(W, X[i-1], out=interior)\n",
    "        numpy.add(interior, trellisfw[i-1], out=interior)\n",
    "        # Compute messages for all transitions\n",
    "        numpy.add(T, interior[:, numpy.newaxis], out=messages)\n",
    "        # Normalize to avoid numerical instability\n",
    "        maxes = messages.max(axis=0)\n",
    "        numpy.add(messages, -1*maxes, out=messages)\n",
    "        numpy.exp(messages, out=messages)\n",
    "        # Sum messages to compute new state values\n",
    "        numpy.sum(messages, axis=0, out=interior)\n",
    "        numpy.log(interior, out=interior)\n",
    "        # Update trellis with log-sums\n",
    "        numpy.add(maxes, interior, out=trellisfw[i])\n",
    "\n",
    "    # Compute final scores\n",
    "    dots = numpy.matmul(W, X[-1])\n",
    "    numpy.add(dots, trellisfw[-1], out=interior)\n",
    "\n",
    "    # Normalize final log-sum to prevent underflow\n",
    "    M = numpy.max(interior)\n",
    "    numpy.add(interior, -1*M, out=interior)\n",
    "    numpy.exp(interior, out=interior)\n",
    "    \n",
    "    # Calculate log partition function (log Z)\n",
    "    log_z = M + math.log(numpy.sum(interior))\n",
    "\n",
    "    # Return the log probability as difference of scores and log partition function\n",
    "    return sum_num - log_z\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def fb_prob(X, W, T):\n",
    "    \"\"\"\n",
    "    Forward-backward algorithm to compute probabilities over label sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input features for each observation in the sequence. Shape: [sequence_length, num_features]\n",
    "    - W: Weight matrix for label features. Shape: [num_labels, num_features]\n",
    "    - T: Transition matrix between labels. Shape: [num_labels, num_labels]\n",
    "    \n",
    "    Returns:\n",
    "    - trellisfw: Forward probabilities. Shape: [sequence_length, num_labels]\n",
    "    - trellisbw: Backward probabilities. Shape: [sequence_length, num_labels]\n",
    "    - log_z: Log partition function, scalar.\n",
    "    \"\"\"\n",
    "    sequence_length, num_features = X.shape\n",
    "    num_labels = W.shape[0]\n",
    "    \n",
    "    # Initialize forward and backward trellises\n",
    "    trellisfw = np.zeros((sequence_length, num_labels))\n",
    "    trellisbw = np.zeros_like(trellisfw)\n",
    "    \n",
    "    # Forward pass\n",
    "    for i in range(1, sequence_length):\n",
    "        # Compute the weighted input features for all labels at this step\n",
    "        weighted_inputs = np.dot(W, X[i-1])\n",
    "        # Update the trellis with contributions from transitions and previous states\n",
    "        for j in range(num_labels):\n",
    "            transition_scores = T[:, j] + trellisfw[i-1]\n",
    "            trellisfw[i, j] = log_sum_exp(weighted_inputs + transition_scores)\n",
    "    \n",
    "    # Backward pass\n",
    "    trellisbw[-1, :] = 0  # Log-probability of 1 at the end of the sequence\n",
    "    for i in range(sequence_length - 2, -1, -1):\n",
    "        # Similar to forward pass but in reverse\n",
    "        weighted_inputs = np.dot(W, X[i+1])\n",
    "        for j in range(num_labels):\n",
    "            transition_scores = T[j, :] + weighted_inputs\n",
    "            trellisbw[i, j] = log_sum_exp(transition_scores + trellisbw[i+1])\n",
    "    \n",
    "    # Compute log partition function using the forward trellis\n",
    "    final_forward_scores = np.dot(W, X[-1]) + trellisfw[-1]\n",
    "    log_z = log_sum_exp(final_forward_scores)\n",
    "    \n",
    "    return trellisfw, trellisbw, log_z\n",
    "\n",
    "def log_sum_exp(scores):\n",
    "    \"\"\"\n",
    "    Numerically stable computation of log-sum-exp.\n",
    "    \n",
    "    Parameters:\n",
    "    - scores: Input array of scores to be summed in log-space.\n",
    "    \n",
    "    Returns:\n",
    "    - result: Log-sum-exp of input scores.\n",
    "    \"\"\"\n",
    "    max_score = np.max(scores)\n",
    "    return max_score + np.log(np.sum(np.exp(scores - max_score)))\n",
    "\n",
    "\n",
    "# The following functions compute gradients for the weight matrix W and transition matrix T respectively\n",
    "# given a single example (X, y), where X is the feature matrix for the sequence and y is the corresponding label sequence.\n",
    "\n",
    "def log_p_wgrad(W, X, y, T):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the log probability with respect to the weight matrix W.\n",
    "    \n",
    "    Parameters:\n",
    "    W : Weight matrix where each row corresponds to the weights for one label.\n",
    "    X : 2D array where each row is the feature vector for one observation.\n",
    "    y : 1D array of labels corresponding to the observations in X.\n",
    "    T : Transition matrix where T[i, j] is the transition weight from label i to label j.\n",
    "    \n",
    "    Returns:\n",
    "    Gradient of the log probability with respect to W.\n",
    "    \"\"\"\n",
    "    grad_W = np.zeros(W.shape)  # Gradient matrix for W\n",
    "    trellisfw, trellisbw, log_z = fb_prob(X, W, T)\n",
    "\n",
    "    # Iterate over the sequence\n",
    "    for i in range(X.shape[0]):\n",
    "        # Combine forward and backward messages\n",
    "        marginal = trellisfw[i] + trellisbw[i]\n",
    "        # Incorporate the evidence from input features\n",
    "        evidence = np.matmul(W, X[i])\n",
    "        # Subtract the log partition function\n",
    "        marginal -= log_z\n",
    "        # Normalize to get probabilities\n",
    "        marginal = np.exp(marginal)\n",
    "\n",
    "        # Calculate the gradient for the current position\n",
    "        for j in range(26):  # Iterate over all possible labels\n",
    "            if j == y[i]:\n",
    "                grad_W[j] += X[i]  # Add the feature vector for the true label\n",
    "            grad_W[j] -= marginal[j] * X[i]  # Subtract the expected feature vector\n",
    "\n",
    "    return grad_W\n",
    "\n",
    "\n",
    "def log_p_tgrad(T, X, y, W):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the log probability with respect to the transition matrix T.\n",
    "    \n",
    "    Parameters:\n",
    "    - T: Transition matrix where T[i, j] is the transition weight from label i to label j.\n",
    "    - X: 2D array where each row is the feature vector for one observation.\n",
    "    - y: 1D array of labels corresponding to the observations in X.\n",
    "    - W: Weight matrix where each row corresponds to the weights for one label.\n",
    "    \n",
    "    Returns:\n",
    "    - grad: Gradient of the log probability with respect to T.\n",
    "    \"\"\"\n",
    "    num_labels = T.shape[0]\n",
    "    grad = np.zeros_like(T)  # Initialize the gradient matrix for T with zeros\n",
    "    \n",
    "    # Compute the forward and backward probabilities and the log partition function (log Z)\n",
    "    trellisfw, trellisbw, log_z = fb_prob(X, W, T)\n",
    "\n",
    "    for i in range(X.shape[0] - 1):\n",
    "        potential = np.zeros_like(T)  # Potential for transitions\n",
    "        \n",
    "        # Calculate potential scores for transitions considering features and transition scores\n",
    "        for j in range(num_labels):\n",
    "            for k in range(num_labels):\n",
    "                potential[j, k] = np.dot(W[j], X[i]) + np.dot(W[k], X[i+1]) + T[j, k]\n",
    "        \n",
    "        potential += trellisfw[i][:, np.newaxis] + trellisbw[i+1]\n",
    "        potential -= log_z  # Normalize by subtracting log partition function\n",
    "        potential = np.exp(potential)  # Convert to probabilities\n",
    "        \n",
    "        # Update the gradient\n",
    "        grad[y[i], y[i+1]] += 1  # Increment gradient for observed transition\n",
    "        grad -= potential  # Subtract expected transition probabilities\n",
    "        \n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X, y, W, and T are already loaded\n",
    "# grad_W = log_p_wgrad(W, X, y, T)\n",
    "# grad_T = log_p_tgrad(T, X, y, W)\n",
    "# The gradients are used in optimization algorithm to update W and T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c23df",
   "metadata": {},
   "source": [
    "**To tackle question 4a, let's follow a systematic approach. We'll implement stochastic optimization using SGD, SGD with momentum, and compare them with LBFGS.** We'll need to:\n",
    "\n",
    "Implement the function to compute the training objective (negative log-likelihood).\n",
    "\n",
    "Implement the callback function for LBFGS to track the progress.\n",
    "\n",
    "Implement SGD and SGD with momentum for stochastic optimization.\n",
    "\n",
    "Tune hyperparameters for SGD, momentum, and LBFGS.\n",
    "\n",
    "Plot the training objective and test error over effective passes for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7091a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of decode input:\n",
      "X: (100, 128) W: (26, 128) T: (26, 26)\n",
      "Shapes of train_struct:\n",
      "dataX: (25953, 128) dataY length: 25953\n",
      "Shapes of model data:\n",
      "W: (26, 128) T: (26, 26)\n",
      "Number of training sequences: 3438\n",
      "First 5 sequences' labels:\n",
      " [array([ 0, 10,  4]), array([14, 12, 12,  0, 13,  3,  8, 13,  6]), array([ 4, 17, 14]), array([13,  4, 23, 15,  4,  2, 19,  4,  3]), array([ 4,  2, 11,  0, 17,  8, 13,  6])]\n",
      "Number of test sequences: 3439\n",
      "First 5 sequences' labels:\n",
      " [array([24, 11, 14, 15,  7, 14, 13,  4]), array([13, 22, 14, 17, 10,  0,  1, 11,  4]), array([ 2,  2, 14, 20, 13, 19,  0,  1,  8, 11,  8, 19, 24]), array([17,  8,  6,  7, 19,  5, 20, 11, 11, 24]), array([ 4,  2, 14, 12, 15, 17,  4, 18, 18])]\n",
      "Number of training examples: 25953\n",
      "Number of test examples: 26198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Parameters (set to default values, tentative for fine-tuning)\n",
    "C = 1000.0  # Regularization parameter\n",
    "B = 128  # Mini-batch size for SGD and momentum\n",
    "learning_rate = 0.01  # Learning rate for SGD and momentum\n",
    "momentum_gamma = 0.9  # Momentum coefficient for SGD with momentum\n",
    "num_epochs = 10  # Number of epochs for SGD and momentum\n",
    "\n",
    "# Read in the data\n",
    "X, W, T = read_decode_input(decode_input_path)\n",
    "trainX, trainY = read_train_struct(train_struct_path)\n",
    "W_model, T_model = read_model(model_path)\n",
    "train_data = read_train(train_data_path)\n",
    "test_data = read_test(test_data_path)\n",
    "\n",
    "# Calculating the number of training and test examples\n",
    "num_train_examples = sum(len(sequence[0]) for sequence in train_data)\n",
    "num_test_examples = sum(len(sequence[0]) for sequence in test_data)\n",
    "num_features = 128  # Number of features for each observation\n",
    "num_classes = 26  # Number of classes/labels\n",
    "\n",
    "# Debug prints\n",
    "print(f'Number of training examples: {num_train_examples}')\n",
    "print(f'Number of test examples: {num_test_examples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d0944bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(vector):\n",
    "    \"\"\"Computes the log of the sum of exponentials of input elements.\"\"\"\n",
    "    a = np.max(vector)\n",
    "    return a + np.log(np.sum(np.exp(vector - a)))\n",
    "\n",
    "\n",
    "def forward_pass(X, T, W):\n",
    "    \"\"\"\n",
    "    Perform the forward pass to compute alpha values.\n",
    "    :param X: Observations/features for a sequence\n",
    "    :param T: Transition matrix\n",
    "    :param W: Weight matrix\n",
    "    :return: Alpha values\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"Compute alpha values in log space to avoid numerical instability.\"\"\"\n",
    "    num_nodes, num_classes = len(X), T.shape[0]\n",
    "    log_alpha = np.zeros((num_nodes, num_classes))\n",
    "    log_T = np.log(T + 1e-10)\n",
    "\n",
    "    # Initialize with the first observation\n",
    "    log_alpha[0] = np.log(np.exp(W @ X[0]) + 1e-10)\n",
    "\n",
    "    # Induction\n",
    "    for k in range(1, num_nodes):\n",
    "        for y_next in range(num_classes):\n",
    "            log_alpha[k, y_next] = log_sum_exp(log_alpha[k-1] + log_T[:, y_next] + (W @ X[k]))\n",
    "\n",
    "    return log_alpha\n",
    "\n",
    "\n",
    "def backward_pass(X, T, W):\n",
    "    \"\"\"\n",
    "    Perform the backward pass to compute beta values.\n",
    "    :param X: Observations/features for a sequence\n",
    "    :param T: Transition matrix\n",
    "    :param W: Weight matrix\n",
    "    :return: Beta values\n",
    "    \"\"\"\n",
    "    num_nodes, num_classes = len(X), T.shape[0]\n",
    "    beta = np.zeros((num_nodes, num_classes))\n",
    "    \n",
    "    # Initialization\n",
    "    beta[-1] = np.ones(num_classes)  # All ones for the last node\n",
    "    \n",
    "    # Induction\n",
    "    for k in range(num_nodes - 2, -1, -1):\n",
    "        for y_prev in range(num_classes):\n",
    "            beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
    "        beta[k] /= np.sum(beta[k])  # Normalize\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def compute_likelihood(X, y, W, T, alpha, beta):\n",
    "    \"\"\"\n",
    "    Compute the likelihood of the label sequence given the observations.\n",
    "\n",
    "    :param X: Observations/features for a sequence\n",
    "    :param y: Labels for a sequence\n",
    "    :param W: Weight matrix\n",
    "    :param T: Transition matrix\n",
    "    :param alpha: Alpha values from the forward pass\n",
    "    :param beta: Beta values from the backward pass\n",
    "    :return: The likelihood of the label sequence given the observations\n",
    "    \"\"\"\n",
    "    num_nodes = len(X)\n",
    "    Z = np.sum(alpha[-1])  # Partition function from the last alpha values\n",
    "\n",
    "    # Compute the joint probability of y and X\n",
    "    joint_prob = 1.0\n",
    "    for k in range(num_nodes):\n",
    "        if k == 0:\n",
    "            joint_prob *= alpha[k, y[k]]\n",
    "        else:\n",
    "            joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
    "    \n",
    "    # Divide joint probability by partition function to get conditional probability\n",
    "    p_y_given_X = joint_prob / Z\n",
    "\n",
    "    return p_y_given_X\n",
    "\n",
    "def compute_objective(W, T, train_data, C):\n",
    "    \"\"\"\n",
    "    Compute the negative log-likelihood objective for CRF.\n",
    "\n",
    "    :param W: Weight matrix of shape (num_classes, num_features)\n",
    "    :param T: Transition matrix of shape (num_classes, num_classes)\n",
    "    :param train_data: List of training examples, where each example is a tuple (X, y)\n",
    "    :param C: Regularization parameter\n",
    "    :return: The negative log-likelihood objective value.\n",
    "    \"\"\"\n",
    "    objective = 0.0\n",
    "    for X, y in train_data:\n",
    "        alpha = forward_pass(X, T, W)\n",
    "        beta = backward_pass(X, T, W)\n",
    "        p_y_given_X = compute_likelihood(X, y, W, T, alpha, beta) + 1e-10\n",
    "        try:\n",
    "            objective -= np.log(p_y_given_X)\n",
    "        except ValueError:\n",
    "            print(f\"Error computing log for p_y_given_X: {p_y_given_X}\")\n",
    "            continue  # Skip this iteration for debugging purposes\n",
    "\n",
    "    regularization = C * (np.linalg.norm(W)**2 + np.linalg.norm(T)**2)\n",
    "    objective += regularization\n",
    "    try:\n",
    "        return objective.item()\n",
    "    except ValueError as e:\n",
    "        print(f\"Objective computation error: {e}\")\n",
    "        return np.nan  # Return NaN to indicate failure\n",
    "\n",
    "\n",
    "\n",
    "def compute_gradients(W, T, mini_batch, C):\n",
    "    \"\"\"\n",
    "    Compute gradients for the weights W and transitions T over a mini-batch.\n",
    "    \n",
    "    Parameters:\n",
    "    W : Weight matrix where each row corresponds to the weights for one label.\n",
    "    T : Transition matrix where T[i, j] is the transition weight from label i to label j.\n",
    "    mini_batch : A mini-batch of training examples.\n",
    "    C : Regularization strength.\n",
    "    \n",
    "    Returns:\n",
    "    W_gradient : Gradient matrix for W.\n",
    "    T_gradient : Gradient matrix for T.\n",
    "    \"\"\"\n",
    "    W_gradient = np.zeros_like(W)\n",
    "    T_gradient = np.zeros_like(T)\n",
    "\n",
    "    # Sum gradients over all examples in the mini-batch\n",
    "    for X, y in mini_batch:\n",
    "        W_gradient += log_p_wgrad(W, X, y, T)\n",
    "        T_gradient += log_p_tgrad(T, X, y, W)\n",
    "    \n",
    "    # Average the gradients and add regularization\n",
    "    W_gradient /= len(mini_batch)\n",
    "    W_gradient -= 2 * C * W  # L2 regularization\n",
    "    T_gradient /= len(mini_batch)\n",
    "    T_gradient -= 2 * C * T  # L2 regularization\n",
    "    \n",
    "    return W_gradient, T_gradient\n",
    "\n",
    "def predict_sequence(X, W, T):\n",
    "    _, trellisfw, log_z = fb_prob(X, W, T)\n",
    "    y_pred = np.argmax(trellisfw, axis=1)  # Predicted labels\n",
    "    return y_pred\n",
    "\n",
    "def compute_error_rate(X_test, y_test, W, T):\n",
    "    errors = 0\n",
    "    for X, y_true in zip(X_test, y_test):\n",
    "        y_pred = predict_sequence(X, W, T)\n",
    "        errors += np.mean(y_pred != y_true)\n",
    "    return errors / len(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd68995",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 60) (2091655782.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 60\u001b[1;36m\u001b[0m\n\u001b[1;33m    plt.legend()plt.label('Test\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 60)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_error(W, T, test_data):\n",
    "    \"\"\"\n",
    "    Compute the label-wise error rate on the test data.\n",
    "    :param W: Weight matrix of shape (num_classes, num_features)\n",
    "    :param T: Transition matrix of shape (num_classes, num_classes)\n",
    "    :param test_data: List of test examples, where each example is a tuple (X, y)\n",
    "    :return: The label-wise error rate.\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    total_labels = 0\n",
    "\n",
    "    for X, y in test_data:\n",
    "        alpha = forward_pass(X, T, W)\n",
    "        y_pred = np.argmax(alpha, axis=1)  # Predict the label with the highest probability at each step\n",
    "        errors += np.sum(y_pred != y)\n",
    "        total_labels += len(y)\n",
    "    \n",
    "    return errors / total_labels\n",
    "\n",
    "\n",
    "# Callback function for LBFGS\n",
    "def lbfgs_callback(xk):\n",
    "    global function_evals_counter, lbfgs_objective_values, lbfgs_test_errors\n",
    "    \n",
    "    # Reshape xk into W and T matrices\n",
    "    W = xk[:num_classes * num_features].reshape(num_classes, num_features)\n",
    "    T = xk[num_classes * num_features:].reshape(num_classes, num_classes)\n",
    "    \n",
    "    # Compute current objective value\n",
    "    current_objective = compute_objective(W, T, train_data, C)\n",
    "    lbfgs_objective_values.append(current_objective)\n",
    "    \n",
    "    # Compute and log the error rate\n",
    "    err_rate = compute_error_rate(X_test, y_test, W, T)\n",
    "    lbfgs_test_errors.append(err_rate)\n",
    "    \n",
    "    # Increase the counter by 1 and print progress\n",
    "    function_evals_counter += 1\n",
    "    print(f\"Iteration {function_evals_counter}: Objective = {current_objective}, Test Error = {current_test_error}\")\n",
    "    \n",
    "    # Optionally, save checkpoint of W and T\n",
    "\n",
    "# Optionally, define a function to plot the progress over time\n",
    "def plot_progress(lbfgs_objective_values, lbfgs_test_errors):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(lbfgs_objective_values, label='Objective value')\n",
    "    plt.title('Objective value over iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Objective value')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(lbfgs_test_errors, label='Test error')\n",
    "    plt.title('Test error over iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Test error')\n",
    "    plt.legend()plt.label('Test\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run optimization algorithm with L-BFGS, callback function will be used to track progress\n",
    "# ...\n",
    "\n",
    "# After optimization, plot the progress\n",
    "#plot_progress(lbfgs_objective_values, lbfgs_test_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(train_data, num_epochs, B, learning_rate, W, T):\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        for i in range(0, len(train_data), B):\n",
    "            mini_batch = train_data[i:i+B]\n",
    "            grad_W_total = np.zeros_like(W)\n",
    "            grad_T_total = np.zeros_like(T)\n",
    "\n",
    "            # Compute gradient for mini-batch\n",
    "            for X, y in mini_batch:\n",
    "                grad_W = log_p_wgrad(W, X, y, T)\n",
    "                grad_T = log_p_tgrad(T, X, y, W)\n",
    "                grad_W_total += grad_W\n",
    "                grad_T_total += grad_T\n",
    "            \n",
    "            # Update the parameters\n",
    "            W += learning_rate * (grad_W_total / B)\n",
    "            T += learning_rate * (grad_T_total / B)\n",
    "            \n",
    "    return W, T\n",
    "\n",
    "\n",
    "def sgd_momentum(train_data, num_epochs, B, learning_rate, momentum_gamma, W, T):\n",
    "    v_W = np.zeros_like(W)\n",
    "    v_T = np.zeros_like(T)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        for i in range(0, len(train_data), B):\n",
    "            mini_batch = train_data[i:i+B]\n",
    "            grad_W_total = np.zeros_like(W)\n",
    "            grad_T_total = np.zeros_like(T)\n",
    "\n",
    "            # Compute gradient for mini-batch\n",
    "            for X, y in mini_batch:\n",
    "                grad_W = log_p_wgrad(W, X, y, T)\n",
    "                grad_T = log_p_tgrad(T, X, y, W)\n",
    "                grad_W_total += grad_W\n",
    "                grad_T_total += grad_T\n",
    "\n",
    "            # Apply momentum updates\n",
    "            v_W = momentum_gamma * v_W - learning_rate * (grad_W_total / B)\n",
    "            v_T = momentum_gamma * v_T - learning_rate * (grad_T_total / B)\n",
    "            \n",
    "            W += v_W\n",
    "            T += v_T\n",
    "            \n",
    "    return W, T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19c8c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numerical_stability(W, T, X):\n",
    "    \"\"\"Check for NaN or infinity in the parameters or data.\"\"\"\n",
    "    if np.isnan(W).any() or np.isinf(W).any():\n",
    "        print(\"Numerical instability in W.\")\n",
    "    if np.isnan(T).any() or np.isinf(T).any():\n",
    "        print(\"Numerical instability in T.\")\n",
    "    for x in X:\n",
    "        if np.isnan(x).any() or np.isinf(x).any():\n",
    "            print(\"Numerical instability in input data.\")\n",
    "            \n",
    "check_numerical_stability(W,T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a598ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the optimization functions\n",
    "W_updated, T_updated = sgd(train_data, num_epochs, B, learning_rate, W, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4db3cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W_updated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_err \u001b[38;5;241m=\u001b[39m test_error(W_updated, T_updated, test_data)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Error after SGD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W_updated' is not defined"
     ]
    }
   ],
   "source": [
    "test_err = test_error(W_updated, T_updated, test_data)\n",
    "print(f'Test Error after SGD: {test_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96d357e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_updated_momentum, T_updated_momentum = sgd_momentum(train_data, num_epochs, B, learning_rate, momentum_gamma, W, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f8ff384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error after SGD momentum: 0.9938544927093671\n"
     ]
    }
   ],
   "source": [
    "test_err = test_error(W_updated_momentum, T_updated_momentum, test_data)\n",
    "print(f'Test Error after SGD momentum: {test_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb903c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "\n",
    "def lbfgs_optimize(W, T, train_data, C, maxiter=100):\n",
    "    # Flatten W and T into a single parameter vector for optimization\n",
    "    initial_params = np.concatenate([W.flatten(), T.flatten()])\n",
    "    \n",
    "    # Define a wrapper for the objective and gradient computation\n",
    "    def objective_and_grad(params):\n",
    "        W = params[:num_classes * num_features].reshape(num_classes, num_features)\n",
    "        T = params[num_classes * num_features:].reshape(num_classes, num_classes)\n",
    "        obj = compute_objective(W, T, train_data, C)\n",
    "        grad_W, grad_T = compute_gradients(W, T, train_data, C)\n",
    "        grad = np.concatenate([grad_W.flatten(), grad_T.flatten()])\n",
    "        return obj, grad\n",
    "\n",
    "    # Optimize using L-BFGS\n",
    "    optimized_params, f, d = fmin_l_bfgs_b(objective_and_grad, initial_params, maxfun=maxiter, callback=lbfgs_callback)\n",
    "    \n",
    "    # Reshape the optimized parameters back into W and T\n",
    "    W_optimized = optimized_params[:num_classes * num_features].reshape(num_classes, num_features)\n",
    "    T_optimized = optimized_params[num_classes * num_features:].reshape(num_classes, num_classes)\n",
    "    \n",
    "    return W_optimized, T_optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3b41028",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m W_sgd, T_sgd \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mcopy(), T\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Create copies to avoid modifying the original parameters\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 9\u001b[0m     W_sgd, T_sgd \u001b[38;5;241m=\u001b[39m sgd(train_data, \u001b[38;5;241m1\u001b[39m, B, learning_rate, W_sgd, T_sgd)\n\u001b[0;32m     10\u001b[0m     obj \u001b[38;5;241m=\u001b[39m compute_objective(W_sgd, T_sgd, train_data, C)\n\u001b[0;32m     11\u001b[0m     err \u001b[38;5;241m=\u001b[39m test_error(W_sgd, T_sgd, test_data)\n",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(train_data, num_epochs, B, learning_rate, W, T)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m mini_batch:\n\u001b[0;32m     11\u001b[0m     grad_W \u001b[38;5;241m=\u001b[39m log_p_wgrad(W, X, y, T)\n\u001b[1;32m---> 12\u001b[0m     grad_T \u001b[38;5;241m=\u001b[39m log_p_tgrad(T, X, y, W)\n\u001b[0;32m     13\u001b[0m     grad_W_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad_W\n\u001b[0;32m     14\u001b[0m     grad_T_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad_T\n",
      "Cell \u001b[1;32mIn[2], line 192\u001b[0m, in \u001b[0;36mlog_p_tgrad\u001b[1;34m(T, X, y, W)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_labels):\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_labels):\n\u001b[1;32m--> 192\u001b[0m         potential[j, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W[j], X[i]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W[k], X[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m T[j, k]\n\u001b[0;32m    194\u001b[0m potential \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m trellisfw[i][:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m+\u001b[39m trellisbw[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    195\u001b[0m potential \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m log_z  \u001b[38;5;66;03m# Normalize by subtracting log partition function\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "function_evals_counter = 0\n",
    "lbfgs_objective_values = []\n",
    "lbfgs_test_errors = []\n",
    "\n",
    "# SGD Optimization\n",
    "sgd_objective_values, sgd_test_errors = [], []\n",
    "W_sgd, T_sgd = W.copy(), T.copy()  # Create copies to avoid modifying the original parameters\n",
    "for epoch in range(num_epochs):\n",
    "    W_sgd, T_sgd = sgd(train_data, 1, B, learning_rate, W_sgd, T_sgd)\n",
    "    obj = compute_objective(W_sgd, T_sgd, train_data, C)\n",
    "    err = test_error(W_sgd, T_sgd, test_data)\n",
    "    sgd_objective_values.append(obj)\n",
    "    sgd_test_errors.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "971c0fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0426662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD with Momentum Optimization\n",
    "sgd_momentum_objective_values, sgd_momentum_test_errors = [], []\n",
    "W_momentum, T_momentum = W.copy(), T.copy()\n",
    "for epoch in range(num_epochs):\n",
    "    W_momentum, T_momentum = sgd_momentum(train_data, 1, B, learning_rate, momentum_gamma, W_momentum, T_momentum)\n",
    "    obj = compute_objective(W_momentum, T_momentum, train_data, C)\n",
    "    err = test_error(W_momentum, T_momentum, test_data)\n",
    "    sgd_momentum_objective_values.append(obj)\n",
    "    sgd_momentum_test_errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_momentum_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24b143e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:19: RuntimeWarning: invalid value encountered in log\n",
      "  log_T = np.log(T + 1e-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  log_alpha[0] = np.log(np.exp(W @ X[0]) + 1e-10)\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:75: RuntimeWarning: overflow encountered in exp\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:75: RuntimeWarning: overflow encountered in multiply\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:75: RuntimeWarning: invalid value encountered in multiply\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:49: RuntimeWarning: overflow encountered in multiply\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1784809121.py:49: RuntimeWarning: invalid value encountered in multiply\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    }
   ],
   "source": [
    "# Flatten W and T for L-BFGS optimization\n",
    "initial_params = np.concatenate([W.flatten(), T.flatten()])\n",
    "\n",
    "# Example L-BFGS call (ensure lbfgs_optimize is implemented correctly)\n",
    "W_lbfgs, T_lbfgs = lbfgs_optimize(W.flatten(), T.flatten(), train_data, C, maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1f5f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_comparison(sgd_objective_values, sgd_test_errors, sgd_momentum_objective_values, sgd_momentum_test_errors, lbfgs_objective_values, lbfgs_test_errors):\n",
    "    max_length = max(len(sgd_objective_values), len(sgd_momentum_objective_values), len(lbfgs_objective_values))\n",
    "    epochs = np.arange(1, max_length + 1)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Plotting training objective\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if sgd_objective_values:\n",
    "        plt.plot(epochs[:len(sgd_objective_values)], sgd_objective_values, label='SGD Objective')\n",
    "    if sgd_momentum_objective_values:\n",
    "        plt.plot(epochs[:len(sgd_momentum_objective_values)], sgd_momentum_objective_values, label='SGD with Momentum Objective')\n",
    "    if lbfgs_objective_values:\n",
    "        plt.plot(epochs[:len(lbfgs_objective_values)], lbfgs_objective_values, label='L-BFGS Objective', linestyle='--')\n",
    "    plt.xlabel('Effective number of passes')\n",
    "    plt.ylabel('Training Objective')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plotting test error\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if sgd_test_errors:\n",
    "        plt.plot(epochs[:len(sgd_test_errors)], sgd_test_errors, label='SGD Test Error')\n",
    "    if sgd_momentum_test_errors:\n",
    "        plt.plot(epochs[:len(sgd_momentum_test_errors)], sgd_momentum_test_errors, label='SGD with Momentum Test Error')\n",
    "    if lbfgs_test_errors:\n",
    "        plt.plot(epochs[:len(lbfgs_test_errors)], lbfgs_test_errors, label='L-BFGS Test Error', linestyle='--')\n",
    "    plt.xlabel('Effective number of passes')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_comparison(\n",
    "    sgd_objective_values, sgd_test_errors,\n",
    "    sgd_momentum_objective_values, sgd_momentum_test_errors,\n",
    "    lbfgs_objective_values, lbfgs_test_errors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b651ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_step(mini_batch, W, T, learning_rate):\n",
    "    W_grad, T_grad = compute_gradients(W, T, mini_batch, C)\n",
    "    W -= learning_rate * W_grad\n",
    "    T -= learning_rate * T_grad\n",
    "    return W, T\n",
    "\n",
    "\n",
    "def sgd_momentum_step(mini_batch, W, T, vW, vT, learning_rate, momentum_gamma):\n",
    "    W_grad, T_grad = compute_gradients(W, T, mini_batch, C)\n",
    "    vW = momentum_gamma * vW - learning_rate * W_grad\n",
    "    vT = momentum_gamma * vT - learning_rate * T_grad\n",
    "    W += vW\n",
    "    T += vT\n",
    "    return W, T, vW, vT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10751d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_optimization(train_data, X_test, y_test, W_init, T_init, num_epochs, batch_size, learning_rate):\n",
    "    W, T = W_init.copy(), T_init.copy()\n",
    "    sgd_objective_values, sgd_test_errors = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            mini_batch = train_data[i:i+batch_size]\n",
    "            W, T = sgd_step(mini_batch, W, T, learning_rate)  # Implement your sgd_step function\n",
    "        \n",
    "        obj = compute_objective(W, T, train_data)  # Implement compute_objective function\n",
    "        error_rate = compute_error_rate(X_test, y_test, W, T)  # Use your compute_error_rate function\n",
    "        sgd_objective_values.append(obj)\n",
    "        sgd_test_errors.append(error_rate)\n",
    "    \n",
    "    return W, T, sgd_objective_values, sgd_test_errors\n",
    "\n",
    "\n",
    "def sgd_momentum_optimization(train_data, X_test, y_test, W_init, T_init, num_epochs, batch_size, learning_rate, momentum):\n",
    "    W, T = W_init.copy(), T_init.copy()\n",
    "    vW, vT = np.zeros_like(W), np.zeros_like(T)\n",
    "    sgd_momentum_objective_values, sgd_momentum_test_errors = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            mini_batch = train_data[i:i+batch_size]\n",
    "            W, T, vW, vT = sgd_momentum_step(mini_batch, W, T, vW, vT, learning_rate, momentum)  # Implement your sgd_momentum_step function\n",
    "        \n",
    "        obj = compute_objective(W, T, train_data)  # Implement compute_objective function\n",
    "        error_rate = compute_error_rate(X_test, y_test, W, T)  # Use your compute_error_rate function\n",
    "        sgd_momentum_objective_values.append(obj)\n",
    "        sgd_momentum_test_errors.append(error_rate)\n",
    "    \n",
    "    return W, T, sgd_momentum_objective_values, sgd_momentum_test_errors\n",
    "\n",
    "\n",
    "\n",
    "def lbfgs_optimize(X_test, y_test, W_init, T_init, train_data, maxiter=100):\n",
    "    initial_params = np.concatenate([W_init.flatten(), T_init.flatten()])\n",
    "    global lbfgs_objective_values, lbfgs_test_errors\n",
    "\n",
    "    def objective_and_grad(params):\n",
    "        W = params[:W_init.size].reshape(W_init.shape)\n",
    "        T = params[W_init.size:].reshape(T_init.shape)\n",
    "        obj = compute_objective(W, T, train_data, C)\n",
    "        grad_W, grad_T = compute_gradients(W, T, train_data, C)  # Implement your compute_gradients function\n",
    "        grad = np.concatenate([grad_W.flatten(), grad_T.flatten()])\n",
    "        return obj, grad\n",
    "    \n",
    "    def callback(params):\n",
    "        global function_evals_counter\n",
    "        W = params[:W_init.size].reshape(W_init.shape)\n",
    "        T = params[W_init.size:].reshape(T_init.shape)\n",
    "        obj = compute_objective(W, T, train_data, C)\n",
    "        error_rate = compute_error_rate(X_test, y_test, W, T)\n",
    "        lbfgs_objective_values.append(obj)\n",
    "        lbfgs_test_errors.append(error_rate)\n",
    "        function_evals_counter += 1\n",
    "\n",
    "    optimized_params, _, _ = fmin_l_bfgs_b(objective_and_grad, initial_params, maxfun=maxiter, callback=callback)\n",
    "    W_optimized = optimized_params[:W_init.size].reshape(W_init.shape)\n",
    "    T_optimized = optimized_params[W_init.size:].reshape(T_init.shape)\n",
    "    \n",
    "    return W_optimized, T_optimized, lbfgs_objective_values, lbfgs_test_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c59ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences: 3438\n",
      "First 5 sequences' labels:\n",
      " [array([ 0, 10,  4]), array([14, 12, 12,  0, 13,  3,  8, 13,  6]), array([ 4, 17, 14]), array([13,  4, 23, 15,  4,  2, 19,  4,  3]), array([ 4,  2, 11,  0, 17,  8, 13,  6])]\n",
      "Number of test sequences: 3439\n",
      "First 5 sequences' labels:\n",
      " [array([24, 11, 14, 15,  7, 14, 13,  4]), array([13, 22, 14, 17, 10,  0,  1, 11,  4]), array([ 2,  2, 14, 20, 13, 19,  0,  1,  8, 11,  8, 19, 24]), array([17,  8,  6,  7, 19,  5, 20, 11, 11, 24]), array([ 4,  2, 14, 12, 15, 17,  4, 18, 18])]\n",
      "Shapes of model data:\n",
      "W: (26, 128) T: (26, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:19: RuntimeWarning: invalid value encountered in log\n",
      "  log_T = np.log(T + 1e-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  log_alpha[0] = np.log(np.exp(W @ X[0]) + 1e-10)\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:75: RuntimeWarning: overflow encountered in exp\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:75: RuntimeWarning: invalid value encountered in multiply\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:49: RuntimeWarning: overflow encountered in multiply\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:75: RuntimeWarning: overflow encountered in multiply\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:49: RuntimeWarning: invalid value encountered in multiply\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    }
   ],
   "source": [
    "train_data = read_train(train_data_path)\n",
    "test_data = read_test(test_data_path)  # test_data is a list of (X, y) tuples \n",
    "\n",
    "X_test = [X for X, _ in test_data]\n",
    "y_test = [y for _, y in test_data]\n",
    "\n",
    "# Initialize W and T using either read_model() or another appropriate method\n",
    "W, T = read_model()\n",
    "\n",
    "\n",
    "function_evals_counter = 0\n",
    "lbfgs_objective_values = []\n",
    "lbfgs_test_errors = []\n",
    "\n",
    "# SGD Optimization\n",
    "W_sgd, T_sgd = W.copy(), T.copy()  # Create copies to avoid modifying the original parameters\n",
    "\n",
    "sgd_objective_values, sgd_test_errors = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    W, T = sgd_step(train_data, W_sgd, T_sgd, learning_rate)\n",
    "    # Compute objective and test error for this epoch\n",
    "    obj = compute_objective(W_sgd, T_sgd, train_data, C)\n",
    "    test_err = compute_error_rate(X_test, y_test, W_sgd, T_sgd)\n",
    "    sgd_objective_values.append(obj)\n",
    "    sgd_test_errors.append(test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0da5d071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9530530154476082,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221,\n",
       " 0.9526567565096221]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3f95e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1023438.py:156: RuntimeWarning: overflow encountered in exp\n",
      "  marginal = np.exp(marginal)\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1023438.py:162: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad_W[j] -= marginal[j] * X[i]  # Subtract the expected feature vector\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\1023438.py:152: RuntimeWarning: invalid value encountered in matmul\n",
      "  evidence = np.matmul(W, X[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    }
   ],
   "source": [
    "# SGD with momentum\n",
    "\n",
    "vW, vT = np.zeros_like(W), np.zeros_like(T)\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(train_data)\n",
    "    for i in range(0, len(train_data), B):\n",
    "        mini_batch = train_data[i:i+B]\n",
    "        W_momentum, T_momentum, vW, vT = sgd_momentum_step(mini_batch, W_momentum, T_momentum, vW, vT, learning_rate, momentum_gamma)\n",
    "    obj = compute_objective(W_momentum, T_momentum, train_data, C)\n",
    "    test_err = compute_error_rate(X_test, y_test, W_momentum, T_momentum)\n",
    "    sgd_momentum_objective_values.append(obj)\n",
    "    sgd_momentum_test_errors.append(test_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f4f05a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9401862737613559,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666,\n",
       " 0.9157183709960666]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_momentum_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607710b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:19: RuntimeWarning: invalid value encountered in log\n",
      "  log_T = np.log(T + 1e-10)\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  log_alpha[0] = np.log(np.exp(W @ X[0]) + 1e-10)\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  beta[k, y_prev] = np.sum(beta[k+1] * T[y_prev, :] * np.exp(W @ X[k+1]))\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:75: RuntimeWarning: overflow encountered in exp\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n",
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_3860\\68444693.py:75: RuntimeWarning: invalid value encountered in multiply\n",
      "  joint_prob *= alpha[k-1, y[k-1]] * T[y[k-1], y[k]] * np.exp(W @ X[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n",
      "Objective computation error: can only convert an array of size 1 to a Python scalar\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming W_init and T_init are your initial W and T matrices for the optimization process\n",
    "W_init, T_init = W.copy(), T.copy()\n",
    "W_lbfgs, T_lbfgs, lbfgs_objective_values, lbfgs_test_errors = lbfgs_optimize( X_test, y_test, W_init, T_init, train_data, maxiter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_optimization_comparison(sgd_obj_values, sgd_err_values,\n",
    "                                 sgd_mom_obj_values, sgd_mom_err_values,\n",
    "                                 lbfgs_obj_values, lbfgs_err_values):\n",
    "    epochs = range(1, len(sgd_obj_values) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plotting training objectives\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, sgd_obj_values, label='SGD Objective', marker='o')\n",
    "    plt.plot(epochs, sgd_mom_obj_values, label='SGD with Momentum Objective', marker='s')\n",
    "    if lbfgs_obj_values:  # Check if L-BFGS data is available\n",
    "        plt.plot(range(1, len(lbfgs_obj_values) + 1), lbfgs_obj_values, label='L-BFGS Objective', linestyle='--')\n",
    "    plt.title('Training Objective over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Objective Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting test errors\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, sgd_err_values, label='SGD Test Error', marker='o')\n",
    "    plt.plot(epochs, sgd_mom_err_values, label='SGD with Momentum Test Error', marker='s')\n",
    "    if lbfgs_err_values:  # Check if L-BFGS data is available\n",
    "        plt.plot(range(1, len(lbfgs_err_values) + 1), lbfgs_err_values, label='L-BFGS Test Error', linestyle='--')\n",
    "    plt.title('Test Error over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function with your data\n",
    "plot_optimization_comparison(sgd_objective_values, sgd_test_errors,\n",
    "                             sgd_momentum_objective_values, sgd_momentum_test_errors,\n",
    "                             lbfgs_objective_values, lbfgs_test_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadf4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
