{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cda0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# this is data_read\n",
    "\n",
    "def read_decode_input():\n",
    "#function to read the data from decode_input\n",
    "#100 letters each 128 elements\n",
    "#26 weight vectors each 128 elements\n",
    "#T which is a 26 x 26 weight matrix\n",
    "#T is row major T_11, T_21, T_31 ..\n",
    "\n",
    "\twith open(\"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/decode_input.txt\", \"r\") as f:\n",
    "\t\traw_data = f.read().split(\"\\n\")\n",
    "\n",
    "\tX = numpy.array(raw_data[:100*128], dtype=float).reshape(100,128)\n",
    "\tW = numpy.array(raw_data[100*128:100*128+26*128]\\\n",
    "\t\t, dtype=float).reshape(26,128)\n",
    "\tT = numpy.array(raw_data[100*128+26*128:-1], dtype=float).reshape(26,26)\n",
    "\tT = numpy.swapaxes(T, 0, 1)\n",
    "\n",
    "\treturn X, W, T\n",
    "\n",
    "def read_train_struct():  #contemplate modifying this for performance reasons\n",
    "#function to read data into list structure\n",
    "#dataX number of examples by 128 currently a numpy array\n",
    "#dataY number of examples by 2 \"array\" (each example has a label and a qid)\n",
    "\n",
    "\twith open(\"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/train_struct.txt\", \"r\") as f:\n",
    "\t\traw_data = f.read()\n",
    "\traw_data = raw_data.split(\"\\n\")\n",
    "\n",
    "\tdataX, dataY = [], []\n",
    "\tfor line in raw_data[:-1]: #-2 because last element is empty\n",
    "\t\tline = line.split(\" \")\n",
    "\t\tdataY.append([ int(line[0])-1, int(line[1][4:]) ])\n",
    "\t\tdatax = [0]*128\n",
    "\t\tfor f1 in line[2:]:\n",
    "\t\t\tend = f1.find(\":\")\n",
    "\t\t\tdatax[int(f1[:end])-1] = 1\n",
    "\t\tdataX.append(datax)\n",
    "\n",
    "\treturn numpy.array(dataX, dtype=float), dataY\n",
    "\n",
    "def read_model():\n",
    "#function to read model for 2a\n",
    "\twith open(\"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/model.txt\", \"r\") as f:\n",
    "\t\traw_data = f.read()\n",
    "\traw_data = raw_data.split(\"\\n\")\n",
    "\n",
    "\tW = numpy.array(raw_data[:26*128], dtype=float).reshape(26, 128)\n",
    "\tT = numpy.array(raw_data[26*128:-1], dtype=float).reshape(26, 26)\n",
    "\tT = numpy.swapaxes(T, 0, 1)\n",
    "\treturn W, T\n",
    "\n",
    "def read_train():\n",
    "#function to read train data\n",
    "\tfrom string import ascii_lowercase\n",
    "\tmapping = list(enumerate(ascii_lowercase))\n",
    "\tmapping = { i[1]:i[0] for i in mapping }\n",
    "\n",
    "\twith open(\"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/train.txt\", \"r\") as f:\n",
    "\t\traw_data = f.read()\n",
    "\traw_data = raw_data.split(\"\\n\")\n",
    "\n",
    "\tdataX, dataY = [], []\n",
    "\ttempX, tempY = [], []\n",
    "\tfor row in raw_data[:-1]:\n",
    "\t\trow = row.split(\" \")\n",
    "\t\ttempY.append( mapping[row[1]])\n",
    "\t\ttempX.append( numpy.array(row[5:], dtype=float) )\n",
    "\t\tif int(row[2]) < 0:\n",
    "\t\t\tdataX.append(numpy.array(tempX))\n",
    "\t\t\tdataY.append(numpy.array(tempY, dtype=int))\n",
    "\t\t\ttempX, tempY = [], []\n",
    "\n",
    "\tret = zip(dataX, dataY)\n",
    "\treturn list(ret)\n",
    "\n",
    "def read_test():\n",
    "#function to read train data\n",
    "\tfrom string import ascii_lowercase\n",
    "\tmapping = list(enumerate(ascii_lowercase))\n",
    "\tmapping = { i[1]:i[0] for i in mapping }\n",
    "\n",
    "\twith open(\"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/test.txt\", \"r\") as f:\n",
    "\t\traw_data = f.read()\n",
    "\traw_data = raw_data.split(\"\\n\")\n",
    "\n",
    "\tdataX, dataY = [], []\n",
    "\ttempX, tempY = [], []\n",
    "\tfor row in raw_data[:-1]:\n",
    "\t\trow = row.split(\" \")\n",
    "\t\ttempY.append( mapping[row[1]])\n",
    "\t\ttempX.append( numpy.array(row[5:], dtype=float) )\n",
    "\t\tif int(row[2]) < 0:\n",
    "\t\t\tdataX.append(numpy.array(tempX))\n",
    "\t\t\tdataY.append(numpy.array(tempY, dtype=int))\n",
    "\t\t\ttempX, tempY = [], []\n",
    "\n",
    "\tret = zip(dataX, dataY)\n",
    "\treturn list(ret)\n",
    "\n",
    "def read_test_decoder_modified(file_path):\n",
    "    \"\"\"\n",
    "    Reads the test data for decoding and returns a NumPy array\n",
    "    where each sub-array from the list becomes a row in the final\n",
    "    two-dimensional array.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        raw_data = file.read().strip().split('\\n')\n",
    "\n",
    "    # Split each line into its components and extract the features\n",
    "    dataX = [list(map(float, row.split(' ')[5:]))\n",
    "             for row in raw_data if row]\n",
    "\n",
    "    # Convert the list of lists (features for each word) into a 2D NumPy array\n",
    "    dataX_np = np.array(dataX)\n",
    "\n",
    "    return dataX_np\n",
    "\n",
    "\n",
    "\n",
    "#This function is similar to your read_test function but without the dataY part, since we only need the X data (features) for decoding #purposes. You might need to adjust the path to \"../data/test.txt\" depending on where your test data file is located relative to the script #that is calling this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942fc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of decode input:\n",
      "X: (100, 128) W: (26, 128) T: (26, 26)\n",
      "Shapes of train_struct:\n",
      "dataX: (25953, 128) dataY length: 25953\n",
      "Shapes of model data:\n",
      "W: (26, 128) T: (26, 26)\n",
      "Number of training sequences: 3438\n",
      "First 5 sequences' labels:\n",
      " [array([ 0, 10,  4]), array([14, 12, 12,  0, 13,  3,  8, 13,  6]), array([ 4, 17, 14]), array([13,  4, 23, 15,  4,  2, 19,  4,  3]), array([ 4,  2, 11,  0, 17,  8, 13,  6])]\n",
      "Number of test sequences: 3439\n",
      "First 5 sequences' labels:\n",
      " [array([24, 11, 14, 15,  7, 14, 13,  4]), array([13, 22, 14, 17, 10,  0,  1, 11,  4]), array([ 2,  2, 14, 20, 13, 19,  0,  1,  8, 11,  8, 19, 24]), array([17,  8,  6,  7, 19,  5, 20, 11, 11, 24]), array([ 4,  2, 14, 12, 15, 17,  4, 18, 18])]\n",
      "Shape of test data for decoder: (26198, 128)\n",
      "Top 5 feature vectors:\n",
      " [[0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      "  0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      "  0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      "  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      "  1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      "  1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      "  1. 1. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define file paths for ease of access\n",
    "decode_input_path = \"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/decode_input.txt\"\n",
    "train_struct_path = \"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/train_struct.txt\"\n",
    "model_path = \"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/model.txt\"\n",
    "train_data_path = \"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/train.txt\"\n",
    "test_data_path = \"C:/Users/prana/Desktop/Fall 23/Adv ML/LAB1/CRF-master/data/test.txt\"\n",
    "\n",
    "def read_decode_input(file_path):\n",
    "    \"\"\"\n",
    "    Reads the decode_input data from the file.\n",
    "    Each line represents one letter with 128 elements.\n",
    "    There are 26 weight vectors each with 128 elements and a transition matrix T with size 26x26.\n",
    "    The transition matrix T is in row-major order.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    X = np.array(raw_data[:100 * 128], dtype=float).reshape(100, 128)\n",
    "    W = np.array(raw_data[100 * 128:100 * 128 + 26 * 128], dtype=float).reshape(26, 128)\n",
    "    T = np.array(raw_data[100 * 128 + 26 * 128:-1], dtype=float).reshape(26, 26)\n",
    "    T = np.swapaxes(T, 0, 1)\n",
    "    \n",
    "    print(\"Shapes of decode input:\")\n",
    "    print(\"X:\", X.shape, \"W:\", W.shape, \"T:\", T.shape)\n",
    "    #print(\"Top 5 rows of X:\\n\", X[:5])\n",
    "\n",
    "    return X, W, T\n",
    "\n",
    "def read_train_struct(file_path):\n",
    "    \"\"\"\n",
    "    Reads the train_struct data from the file.\n",
    "    Each line represents a label and a feature vector (in a sparse representation).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    for line in raw_data[:-1]:  # The last element is empty\n",
    "        line = line.split(\" \")\n",
    "        dataY.append([int(line[0]) - 1, int(line[1][4:])])\n",
    "        datax = np.zeros(128, dtype=int)\n",
    "        for f1 in line[2:]:\n",
    "            idx, val = f1.split(\":\")\n",
    "            datax[int(idx) - 1] = int(val)\n",
    "        dataX.append(datax)\n",
    "    \n",
    "    dataX_np = np.array(dataX, dtype=int)\n",
    "    print(\"Shapes of train_struct:\")\n",
    "    print(\"dataX:\", dataX_np.shape, \"dataY length:\", len(dataY))\n",
    "    #print(\"Top 5 rows of dataX:\\n\", dataX_np[:5])\n",
    "    \n",
    "    return dataX_np, dataY\n",
    "\n",
    "def read_model(file_path):\n",
    "    \"\"\"\n",
    "    Reads the model data from the file.\n",
    "    The data consists of weight vectors for each label and a transition matrix T.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    W = np.array(raw_data[:26 * 128], dtype=float).reshape(26, 128)\n",
    "    T = np.array(raw_data[26 * 128:-1], dtype=float).reshape(26, 26)\n",
    "    T = np.swapaxes(T, 0, 1)\n",
    "    \n",
    "    print(\"Shapes of model data:\")\n",
    "    print(\"W:\", W.shape, \"T:\", T.shape)\n",
    "    #print(\"Top 5 rows of W:\\n\", W[:5])\n",
    "    \n",
    "    return W, T\n",
    "\n",
    "def read_train(file_path):\n",
    "    \"\"\"\n",
    "    Reads the train data from the file.\n",
    "    Each row corresponds to an example and is split into the label and the feature vector.\n",
    "    \"\"\"\n",
    "    from string import ascii_lowercase\n",
    "    mapping = {letter: idx for idx, letter in enumerate(ascii_lowercase)}\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    tempX, tempY = [], []\n",
    "    for row in raw_data[:-1]:\n",
    "        row = row.split(\" \")\n",
    "        tempY.append(mapping[row[1]])\n",
    "        tempX.append(np.array(row[5:], dtype=float))\n",
    "        if int(row[2]) < 0:  # End of sequence\n",
    "            dataX.append(np.array(tempX))\n",
    "            dataY.append(np.array(tempY, dtype=int))\n",
    "            tempX, tempY = [], []  # Reset for the next sequence\n",
    "\n",
    "    print(\"Number of training sequences:\", len(dataX))\n",
    "    print(\"First 5 sequences' labels:\\n\", dataY[:5])\n",
    "    \n",
    "    return list(zip(dataX, dataY))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_test(file_path):\n",
    "    \"\"\"\n",
    "    Reads the test data from the file.\n",
    "    Each row corresponds to an example and is split into the label and the feature vector.\n",
    "    The function assumes that each example ends when a row with the third column less than 0 is encountered.\n",
    "    \"\"\"\n",
    "    from string import ascii_lowercase\n",
    "    mapping = {letter: idx for idx, letter in enumerate(ascii_lowercase)}\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        raw_data = f.read().split(\"\\n\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    tempX, tempY = [], []\n",
    "    for row in raw_data[:-1]:  # Skip the last empty line if it exists\n",
    "        row = row.split(\" \")\n",
    "        tempY.append(mapping[row[1]])\n",
    "        tempX.append(np.array(row[5:], dtype=float))\n",
    "        if int(row[2]) < 0:  # Check for the end of a sequence\n",
    "            dataX.append(np.array(tempX))\n",
    "            dataY.append(np.array(tempY, dtype=int))\n",
    "            tempX, tempY = [], []  # Reset for the next sequence\n",
    "\n",
    "    print(\"Number of test sequences:\", len(dataX))\n",
    "    print(\"First 5 sequences' labels:\\n\", dataY[:5])\n",
    "\n",
    "    return list(zip(dataX, dataY))\n",
    "\n",
    "def read_test_decoder_modified(file_path):\n",
    "    \"\"\"\n",
    "    Reads the test data for decoding and returns a NumPy array\n",
    "    where each sub-array from the list becomes a row in the final\n",
    "    two-dimensional array. This function only extracts the features\n",
    "    and does not deal with the labels.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        raw_data = file.read().strip().split('\\n')\n",
    "\n",
    "    # Initialize an empty list to store all feature vectors\n",
    "    dataX = []\n",
    "    \n",
    "    for row in raw_data:\n",
    "        if row:  # Skip any empty lines\n",
    "            features = row.split(' ')[5:]  # Features start from the 6th element in the row\n",
    "            feature_vector = list(map(float, features))  # Convert string features to float\n",
    "            dataX.append(feature_vector)\n",
    "\n",
    "    # Convert the list of lists (features for each word) into a 2D NumPy array\n",
    "    dataX_np = np.array(dataX)\n",
    "\n",
    "    print(\"Shape of test data for decoder:\", dataX_np.shape)\n",
    "    print(\"Top 5 feature vectors:\\n\", dataX_np[:5, :])\n",
    "\n",
    "    return dataX_np\n",
    "\n",
    "\n",
    "# Example:\n",
    "X, W, T = read_decode_input(decode_input_path)\n",
    "train_struct_X, train_struct_Y = read_train_struct(train_struct_path)\n",
    "W_model, T_model = read_model(model_path)\n",
    "train_data = read_train(train_data_path)\n",
    "test_data = read_test(test_data_path)\n",
    "test_data_decoder = read_test_decoder_modified(test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e6b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
